{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>samples</th>\n",
       "      <th>Samples Exist Locally</th>\n",
       "      <th>Candidates Greedy Exist Locally</th>\n",
       "      <th>Candidates Multiple Exist Locally</th>\n",
       "      <th>Samples Exist on Alvis</th>\n",
       "      <th>Candidates Greedy Exist on Alvis</th>\n",
       "      <th>Candidates Multiple Exist on Alvis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEvalJava meta-llama/CodeLlama-7b-Instruct-hf</td>\n",
       "      <td>samples_HumanEvalJava_sigonly-instruct_.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GitBugJava meta-llama/CodeLlama-7b-Instruct-hf</td>\n",
       "      <td>samples_GitBugJava_sigonly-instruct_.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Defects4J meta-llama/CodeLlama-7b-Instruct-hf</td>\n",
       "      <td>samples_Defects4J_sigonly-instruct_.jsonl</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  HumanEvalJava meta-llama/CodeLlama-7b-Instruct-hf   \n",
       "1     GitBugJava meta-llama/CodeLlama-7b-Instruct-hf   \n",
       "2      Defects4J meta-llama/CodeLlama-7b-Instruct-hf   \n",
       "\n",
       "                                         samples  Samples Exist Locally  \\\n",
       "0  samples_HumanEvalJava_sigonly-instruct_.jsonl                   True   \n",
       "1     samples_GitBugJava_sigonly-instruct_.jsonl                   True   \n",
       "2      samples_Defects4J_sigonly-instruct_.jsonl                   True   \n",
       "\n",
       "   Candidates Greedy Exist Locally  Candidates Multiple Exist Locally  \\\n",
       "0                            False                              False   \n",
       "1                            False                              False   \n",
       "2                            False                              False   \n",
       "\n",
       "   Samples Exist on Alvis  Candidates Greedy Exist on Alvis  \\\n",
       "0                    True                              True   \n",
       "1                    True                              True   \n",
       "2                    True                             False   \n",
       "\n",
       "   Candidates Multiple Exist on Alvis  \n",
       "0                               False  \n",
       "1                               False  \n",
       "2                               False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "from os import PathLike, path\n",
    "from paramiko.client import SSHClient, AutoAddPolicy\n",
    "from typing import List, Tuple, TypeAlias, Generator, Iterable\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from huggingface_hub import list_datasets\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "from itertools import islice\n",
    "from functools import wraps, reduce\n",
    "from util import get_jobfiles_info, BASE_DIR\n",
    "\n",
    "FILL_IN_THE_MIDDLE = \"fill-in-the-middle\"\n",
    "ZERO_SHOT_CLOZE = \"zero-shot-cloze\"\n",
    "SIGNATURE_ONLY_INSTRUCT = \"sigonly-instruct\"\n",
    "\n",
    "joblist = [\n",
    "    # 7b model data sigonly\n",
    "    (\"HumanEvalJava\", SIGNATURE_ONLY_INSTRUCT, \"codellama-instruct\", \"meta-llama/CodeLlama-7b-Instruct-hf\", \"0.8\"),\n",
    "    (\"GitBugJava\", SIGNATURE_ONLY_INSTRUCT, \"codellama-instruct\", \"meta-llama/CodeLlama-7b-Instruct-hf\", \"0.8\"),\n",
    "    (\"Defects4J\", SIGNATURE_ONLY_INSTRUCT, \"codellama-instruct\", \"meta-llama/CodeLlama-7b-Instruct-hf\", \"0.8\"),\n",
    "    # 13b model data sigonly\n",
    "    # (\"HumanEvalJava\", SIGNATURE_ONLY_INSTRUCT, \"codellama-infilling\", \"meta-llama/CodeLlama-13b-Instruct-hf\", \"0.8\"),\n",
    "    # (\"GitBugJava\", SIGNATURE_ONLY_INSTRUCT, \"codellama-infilling\", \"meta-llama/CodeLlama-13b-Instruct-hf\", \"0.8\"),\n",
    "    # (\"Defects4J\", SIGNATURE_ONLY_INSTRUCT, \"codellama-infilling\", \"meta-llama/CodeLlama-13b-Instruct-hf\", \"0.8\"),\n",
    "]\n",
    "\n",
    "# Spec for running the generation and candidate generation\n",
    "tableitems = []\n",
    "for job in joblist:\n",
    "    DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE = job\n",
    "    info = get_jobfiles_info(*job)\n",
    "    tableitems.append(\n",
    "        (\n",
    "            f\"{DATASET} {CANDIDATE_MODEL_NAME}\", info.samples_file,\n",
    "            info.samples_exists,             info.candidates_greedy_exists,           info.candidates_multiple_exists, \n",
    "        )\n",
    "    )\n",
    "import pandas as pd\n",
    "\n",
    "labels = [\"Title\", \"Samples\", \"Samples Exist Locally\", \"Candidates Greedy Exist Locally\", \"Candidates Multiple Exist Locally\", \"Samples Exist on Alvis\", \"Candidates Greedy Exist on Alvis\", \"Candidates Multiple Exist on Alvis\"]\n",
    "\n",
    "files_df = pd.DataFrame(tableitems, columns=labels)\n",
    "files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing GitBug-Java benchmark...\n",
      "INFO:root:Found 199 bugs\n",
      "Loading GitBug-Java: 100%|██████████| 199/199 [05:10<00:00,  1.56s/it]\n",
      "INFO:root:Building the prompts...\n",
      "  0%|          | 0/199 [00:00<?, ?it/s]ERROR:root:Error while generating sample for bug ezylang-EvalEx-7c39c5478a39: Traceback (most recent call last):\n",
      "  File \"/mnt/data/adahen/elle-elle-aime/generate_samples.py\", line 65, in entry_point\n",
      "    results.append(future.result())\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/mnt/data/adahen/elle-elle-aime/generate_samples.py\", line 23, in generate_sample\n",
      "    return prompt_strategy_obj.prompt(bug)\n",
      "  File \"/mnt/data/adahen/elle-elle-aime/elleelleaime/sample/strategies/sigonly.py\", line 84, in prompt\n",
      "    buggy_code, _ = extract_single_function(bug)\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "\n",
      "  1%|          | 1/199 [00:11<38:55, 11.80s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython generate_samples.py \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMETHOD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --model_name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAMPLE_MODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run cmd in LOCAL_BASE_DIR\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL_BASE_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmove(info\u001b[38;5;241m.\u001b[39msamples_file, info\u001b[38;5;241m.\u001b[39mDATA_DATASET_DIR)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated samples for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMETHOD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAMPLE_MODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Moved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;241m.\u001b[39mDATA_DATASET_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/199 [00:54<1:38:07, 29.89s/it]"
     ]
    }
   ],
   "source": [
    "for DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE in joblist:\n",
    "    info = get_jobfiles_info(DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE)\n",
    "    if info.samples_exists:\n",
    "        print(f\"Samples file {info.samples_file} exists locally. Skipping generation.\")\n",
    "        continue\n",
    "    \n",
    "    # Generate the samples\n",
    "    cmd = f\"python generate_samples.py {DATASET} {METHOD}\"\n",
    "    # Run cmd in LOCAL_BASE_DIR\n",
    "    res = subprocess.run(cmd, shell=True, cwd=BASE_DIR)\n",
    "    # shutil.move(path(), info.DATA_DATASET_DIR)\n",
    "    # print(f\"Generated samples for {DATASET} {METHOD} {SAMPLE_MODEL_NAME}. Moved to {info.DATA_DATASET_DIR}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'samples_HumanEvalJava_sigonly-instruct_.jsonl' was created.\n",
      "File 'samples_GitBugJava_sigonly-instruct_.jsonl' was created.\n",
      "File 'samples_Defects4J_sigonly-instruct_.jsonl' was created.\n"
     ]
    }
   ],
   "source": [
    "# # Move the samples to the server\n",
    "# for DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE in joblist:\n",
    "#     info = get_jobfiles_info(DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE)\n",
    "#     samples_file = info.samples_file\n",
    "#     samples_exists_on_alvis = info.samples_exists_on_alvis\n",
    "#     DATA_DATASET_DIR = info.DATA_DATASET_DIR\n",
    "\n",
    "#     if samples_exists_on_alvis:\n",
    "#         print(f\"File '{samples_file}' already exists on alvis. Skipping.\")\n",
    "#         continue\n",
    "    \n",
    "#     samples_file_data_path = os.path.join(DATA_DATASET_DIR, samples_file)\n",
    "#     with open(samples_file_data_path, \"rb\") as f:\n",
    "#         # convert data to gzip\n",
    "#         samples_data_gz = gzip.compress(f.read())\n",
    "\n",
    "#     # send to alvis\n",
    "#     replaced = write_alvis(f\"{samples_file}.gz\", samples_data_gz)\n",
    "#     print(f\"File '{samples_file}' was {'replaced' if replaced else 'created'}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File greedy already exists on alvis. Skipping.\n",
      "File greedy already exists on alvis. Skipping.\n",
      "File job_greedy_6c80107c353538c9.sh replaced.\n",
      "Job job_greedy_6c80107c353538c9.sh submitted.\n"
     ]
    }
   ],
   "source": [
    "# Generate the script template, then run job to generate GREEDY patches on alvis\n",
    "for DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE in joblist[:3]:\n",
    "    info = get_jobfiles_info(DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE)\n",
    "    template_values = {\n",
    "        \"dataset\": DATASET,\n",
    "        \"method\": METHOD,\n",
    "        \"patch_strategy\": PATCH_STRATEGY,\n",
    "        \"candidate_model_name\": CANDIDATE_MODEL_NAME,\n",
    "    }\n",
    "\n",
    "    if info.candidates_greedy_exists:\n",
    "        print(f\"File greedy already exists. Skipping.\")\n",
    "        continue\n",
    "    if not info.samples_exists:\n",
    "        print(f\"Required file does not exist. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    BASH_TEMPLATE_GREEDY = f\"bash_template_greedy.sh\"\n",
    "    with open(BASH_TEMPLATE_GREEDY, \"r\") as f:\n",
    "        bash_template = f.read()\n",
    "    bash_script_data = str(reduce(lambda acc, kv: acc.replace(f\"<<{kv[0]}>>\", kv[1]), template_values.items(), bash_template))\n",
    "    # Generate hash for run\n",
    "    hash_run = abs(hash(tuple(template_values.items())))\n",
    "    script_greedy_file_name = f\"job_greedy_{hash_run:x}.sh\"\n",
    "    JOBFILES_DIR = os.path.join(BASE_DIR, \"jobfiles\")\n",
    "\n",
    "    # TODO: OLD\n",
    "    # script_greedy_exists_on_alvis = bool(ssh_alvis([f\"ls {script_greedy_file_name}\"], base_path=JOBFILES_DIR))\n",
    "    # # Write to alvis1\n",
    "    # replaced = write_alvis(script_greedy_file_name, bash_script_data.encode(), base_path=ALVIS_JOBFILES_DIR, replace=True)\n",
    "    # print(f\"File {script_greedy_file_name} {'replaced' if replaced else 'created'}.\")\n",
    "    # # Execute the script on the remote server\n",
    "    # ssh_alvis([f\"sbatch {os.path.join('jobfiles', script_greedy_file_name)}\"])\n",
    "    # print(f\"Job {script_greedy_file_name} submitted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File job_multiple_43f9cf4776f9e633.sh created.\n",
      "Job job_multiple_43f9cf4776f9e633.sh submitted.\n",
      "File job_multiple_40e00a519689f392.sh created.\n",
      "Job job_multiple_40e00a519689f392.sh submitted.\n",
      "File job_multiple_36c8dbd7ee6c049f.sh created.\n",
      "Job job_multiple_36c8dbd7ee6c049f.sh submitted.\n"
     ]
    }
   ],
   "source": [
    "# Generate the script template, then run job to generate MULTIPLE patches on alvis\n",
    "\n",
    "for DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE in joblist:\n",
    "    info = get_jobfiles_info(DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE)\n",
    "    template_values = {\n",
    "        \"dataset\": DATASET,\n",
    "        \"method\": METHOD,\n",
    "        \"patch_strategy\": PATCH_STRATEGY,\n",
    "        \"candidate_model_name\": CANDIDATE_MODEL_NAME,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "    }\n",
    "\n",
    "    if info.candidates_multiple_exists:\n",
    "        print(f\"File multiple already exists. Skipping.\")\n",
    "        continue\n",
    "    if not info.samples_exists:\n",
    "        print(f\"Required file does not exist. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    BASH_TEMPLATE_MULTIPLE = f\"bash_template_multiple.sh\"\n",
    "    with open(BASH_TEMPLATE_MULTIPLE, \"r\") as f:\n",
    "        bash_template = f.read()\n",
    "    bash_script_data = str(reduce(lambda acc, kv: acc.replace(f\"<<{kv[0]}>>\", kv[1]), template_values.items(), bash_template))\n",
    "    # Generate hash for run\n",
    "    hash_run = abs(hash(tuple(template_values.items())))\n",
    "    script_multiple_file_name = f\"job_multiple_{hash_run:x}.sh\"\n",
    "    ALVIS_JOBFILES_DIR = os.path.join(BASE_DIR, \"jobfiles\")\n",
    "\n",
    "    # TODO: OLD\n",
    "    # script_multiple_exists_on_alvis = bool(ssh_alvis([f\"ls {script_multiple_file_name}\"], base_path=ALVIS_JOBFILES_DIR))\n",
    "    # if not script_multiple_exists_on_alvis:\n",
    "    #     # Write to alvis1\n",
    "    #     replaced = write_alvis(script_multiple_file_name, bash_script_data.encode(), base_path=ALVIS_JOBFILES_DIR)\n",
    "    #     print(f\"File {script_multiple_file_name} {'replaced' if replaced else 'created'}.\")\n",
    "    # else:\n",
    "    #     print(f\"File {script_multiple_file_name} already exists on alvis. Skipping.\")\n",
    "    # # Execute the script on the remote server\n",
    "    # ssh_alvis([f\"sbatch {os.path.join('jobfiles', script_multiple_file_name)}\"])\n",
    "    # print(f\"Job {script_multiple_file_name} submitted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'samples_HumanEvalJava_sigonly-instruct_.jsonl' already exists in the data folder. Skipping.\n",
      "File 'samples_GitBugJava_sigonly-instruct_.jsonl' already exists in the data folder. Skipping.\n",
      "File 'samples_Defects4J_sigonly-instruct_.jsonl' already exists in the data folder. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# # Read the samples from the server\n",
    "# for DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE in joblist:\n",
    "#     info = get_jobfiles_info(DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE)\n",
    "#     if not info.samples_exists_on_alvis:\n",
    "#         print(f\"File '{info.samples_file}' does not exist on alvis. Skipping.\")\n",
    "#         continue\n",
    "#     if info.samples_exists:\n",
    "#         print(f\"File '{info.samples_file}' already exists in the data folder. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Read from alvis\n",
    "#     data_gz = read_alvis(f\"{info.samples_file}.gz\")\n",
    "#     data = gzip.decompress(data_gz)\n",
    "#     # Create the directory if it does not exist\n",
    "#     print(\"Writing to: \", info.samples_data_dir_path)\n",
    "#     with open(info.samples_data_dir_path, \"wb\") as f:\n",
    "#         # Write bytes to file\n",
    "#         f.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required file does not exist on alvis. Skipping.\n",
      "Required file does not exist on alvis. Skipping.\n",
      "Required file does not exist on alvis. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# # Read the greedy candidates from the server\n",
    "# for DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE in joblist:\n",
    "#     info = get_jobfiles_info(DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE)\n",
    "#     if info.candidates_greedy_exists:\n",
    "#         print(f\"File already exists in the data folder. Skipping.\")\n",
    "#         continue\n",
    "#     if not info.candidates_greedy_exists_on_alvis:\n",
    "#         print(f\"Required file does not exist on alvis. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Read from alvis\n",
    "#     data_gz = read_alvis(f\"{info.candidates_greedy_file}.gz\")\n",
    "#     data = gzip.decompress(data_gz)\n",
    "#     # Create the directory if it does not exist\n",
    "#     print(\"Writing to: \", info.candidates_greedy_data_dir_path)\n",
    "#     with open(info.candidates_greedy_data_dir_path, \"wb\") as f:\n",
    "#         # Write bytes to file\n",
    "#         f.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required file does not exist on alvis. Skipping.\n",
      "Required file does not exist on alvis. Skipping.\n",
      "Required file does not exist on alvis. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# # Read the multiple candidates from the server\n",
    "# for DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE in joblist:\n",
    "#     info = get_jobfiles_info(DATASET, METHOD, PATCH_STRATEGY, CANDIDATE_MODEL_NAME, TEMPERATURE)\n",
    "#     if info.candidates_multiple_exists:\n",
    "#         print(f\"File already exists in the data folder. Skipping.\")\n",
    "#         continue\n",
    "#     if not info.candidates_multiple_exists_on_alvis:\n",
    "#         print(f\"Required file does not exist on alvis. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Read from alvis\n",
    "#     data_gz = read_alvis(f\"{info.candidates_multiple_file}.gz\")\n",
    "#     data = gzip.decompress(data_gz)\n",
    "#     # Create the directory if it does not exist\n",
    "#     print(\"Writing to: \", info.candidates_multiple_data_dir_path)\n",
    "#     with open(info.candidates_multiple_data_dir_path, \"wb\") as f:\n",
    "#         # Write bytes to file\n",
    "#         f.write(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elleelleaime-Ymc4Ofxq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
