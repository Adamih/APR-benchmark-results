{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCD and TED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from os import PathLike, path\n",
    "from paramiko.client import SSHClient, AutoAddPolicy\n",
    "from typing import List, Tuple, TypeAlias, Generator, Iterable\n",
    "from huggingface_hub import list_datasets\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from functools import wraps, reduce\n",
    "import shutil\n",
    "from util import load_jsonl, get_samples, get_samples_greedy, gpto_get_samples, gpto_get_samples_greedy, tokenize_code, get_edit_distance_distribution_star, calculate_ratio, openai_get_samples_instruct, openai_get_samples_greedy_instruct\n",
    "\n",
    "Tokens: TypeAlias = List[int]\n",
    "\n",
    "alpha: float = 0.05\n",
    "xi: float = 0.01\n",
    "max_length: int = 100\n",
    "\n",
    "conf_list = [\n",
    "    # # GPT-4o\n",
    "    # {\n",
    "    #     \"identifier\": \"Defect4J gpt-4o 2024-08-06\",\n",
    "    #     \"greedy_path\": \"data/gpt-4o/defects4j/greedy/candidates_defects4j_instruct_openai-chatcompletion_model_name=gpt-4o-2024-08-06_temperature=0.0_n_samples=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/gpt-4o/defects4j/multiple/candidates_defects4j_instruct_openai-chatcompletion_model_name=gpt-4o-2024-08-06_n_samples=10_temperature=1.0.jsonl\",\n",
    "    #     \"method\": \"gpt-4o\",\n",
    "    #     \"tokenizer\": \"Xenova/gpt-4o\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava gpt-4o 2024-08-06\",\n",
    "    #     \"greedy_path\": \"data/gpt-4o/gitbug-java/greedy/candidates_gitbugjava_instruct_openai-chatcompletion_model_name=gpt-4o-2024-08-06_temperature=0.0_n_samples=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/gpt-4o/gitbug-java/multiple/candidates_gitbugjava_instruct_openai-chatcompletion_model_name=gpt-4o-2024-08-06_n_samples=10_temperature=1.0.jsonl\",\n",
    "    #     \"method\": \"gpt-4o\",\n",
    "    #     \"tokenizer\": \"Xenova/gpt-4o\"\n",
    "    # },\n",
    "    # # GitBugJava starcoder\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava starcoder\",\n",
    "    #     \"greedy_path\": \"data/starcoder/gitbug-java/greedy/candidates_GitBugJava_fill-in-the-middle_starcoder_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoder/gitbug-java/multiple/candidates_GitBugJava_fill-in-the-middle_starcoder_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoder\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava starcoderbase-1b\",\n",
    "    #     \"greedy_path\": \"data/starcoderbase-1b/gitbug-java/greedy/candidates_GitBugJava_fill-in-the-middle_starcoderbase-1b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoderbase-1b/gitbug-java/multiple/candidates_GitBugJava_fill-in-the-middle_starcoderbase-1b_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoderbase-1b\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava starcoderplus\",\n",
    "    #     \"greedy_path\": \"data/starcoderplus/gitbug-java/greedy/candidates_GitBugJava_fill-in-the-middle_starcoderplus_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoderplus/gitbug-java/multiple/candidates_GitBugJava_fill-in-the-middle_starcoderplus_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoderplus\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava starcoder t=0.8\",\n",
    "    #     \"greedy_path\": \"data/starcoder/gitbug-java/greedy/candidates_GitBugJava_fill-in-the-middle_starcoder_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoder/gitbug-java/multiple/candidates_GitBugJava_fill-in-the-middle_starcoder_temperature=0.8_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoder\"\n",
    "    # },\n",
    "    # # HumanEvalJava starcoder\n",
    "    # {\n",
    "    #     \"identifier\": \"HumanEvalJava starcoder\",\n",
    "    #     \"greedy_path\": \"data/starcoder/humaneval-java/greedy/candidates_HumanEvalJava_fill-in-the-middle_starcoder_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoder/humaneval-java/multiple/candidates_HumanEvalJava_fill-in-the-middle_starcoder_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoder\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"HumanEvalJava starcoderbase-1b\",\n",
    "    #     \"greedy_path\": \"data/starcoderbase-1b/humaneval-java/greedy/candidates_HumanEvalJava_fill-in-the-middle_starcoderbase-1b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoderbase-1b/humaneval-java/multiple/candidates_HumanEvalJava_fill-in-the-middle_starcoderbase-1b_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoderbase-1b\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"HumanEvalJava starcoderplus\",\n",
    "    #     \"greedy_path\": \"data/starcoderplus/humaneval-java/greedy/candidates_HumanEvalJava_fill-in-the-middle_starcoderplus_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoderplus/humaneval-java/multiple/candidates_HumanEvalJava_fill-in-the-middle_starcoderplus_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoderplus\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"HumanEvalJava starcoder t=0.8\",\n",
    "    #     \"greedy_path\": \"data/starcoder/humaneval-java/greedy/candidates_HumanEvalJava_fill-in-the-middle_starcoder_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoder/humaneval-java/multiple/candidates_HumanEvalJava_fill-in-the-middle_starcoder_temperature=0.8_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoder\"\n",
    "    # },\n",
    "    # # Defects4J starcoder\n",
    "    # {\n",
    "    #     \"identifier\": \"Defects4J starcoder\",\n",
    "    #     \"greedy_path\": \"data/starcoder/defects4j/greedy/candidates_Defects4J_fill-in-the-middle_starcoder_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoder/defects4j/multiple/candidates_Defects4J_fill-in-the-middle_starcoder_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoder\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"Defects4J starcoderbase-1b\",\n",
    "    #     \"greedy_path\": \"data/starcoderbase-1b/defects4j/greedy/candidates_Defects4J_fill-in-the-middle_starcoderbase-1b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoderbase-1b/defects4j/multiple/candidates_Defects4J_fill-in-the-middle_starcoderbase-1b_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoderbase-1b\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"Defects4J starcoderplus\",\n",
    "    #     \"greedy_path\": \"data/starcoderplus/defects4j/greedy/candidates_Defects4J_fill-in-the-middle_starcoderplus_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoderplus/defects4j/multiple/candidates_Defects4J_fill-in-the-middle_starcoderplus_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoderplus\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"Defects4J starcoder t=0.8\",\n",
    "    #     \"greedy_path\": \"data/starcoder/defects4j/greedy/candidates_Defects4J_fill-in-the-middle_starcoder_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/starcoder/defects4j/multiple/candidates_Defects4J_fill-in-the-middle_starcoder_temperature=0.8_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"bigcode/starcoder\"\n",
    "    # },\n",
    "    # # TODO: Add the codellama-7b models\n",
    "    # # Defects4J codellama-7b\n",
    "    # {\n",
    "    #     \"identifier\": \"Defects4J codellama-7b\",\n",
    "    #     \"greedy_path\": \"data/codellama-7b/defects4j/greedy/candidates_Defects4J_fill-in-the-middle_codellama-7b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/codellama-7b/defects4j/multiple/candidates_Defects4J_fill-in-the-middle_codellama-7b_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"codellama/CodeLlama-7b-hf\"\n",
    "    # },\n",
    "    # # HumanEvalJava codellama-7b\n",
    "    # {\n",
    "    #     \"identifier\": \"HumanEvalJava codellama-7b\",\n",
    "    #     \"greedy_path\": \"data/codellama-7b/humaneval-java/greedy/candidates_HumanEvalJava_fill-in-the-middle_codellama-7b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/codellama-7b/humaneval-java/multiple/candidates_HumanEvalJava_fill-in-the-middle_codellama-7b_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"codellama/CodeLlama-7b-hf\"\n",
    "    # },\n",
    "    # # GitBugJava codellama-7b\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava codellama-7b\",\n",
    "    #     \"greedy_path\": \"data/codellama-7b/gitbug-java/greedy/candidates_GitBugJava_fill-in-the-middle_codellama-7b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/codellama-7b/gitbug-java/multiple/candidates_GitBugJava_fill-in-the-middle_codellama-7b_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"starcoder\",\n",
    "    #     \"tokenizer\": \"codellama/CodeLlama-7b-hf\"\n",
    "    # },\n",
    "    # # HumanEvalJava codellama-7b sigonly t=0.8,\n",
    "    # {\n",
    "    #     \"identifier\": \"HumanEvalJava codellama-7b sigonly t=0.8\",\n",
    "    #     \"greedy_path\": \"data/codellama-7b/humaneval-java/greedy/candidates_HumanEvalJava_sigonly_codellama-7b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/codellama-7b/humaneval-java/multiple/candidates_HumanEvalJava_sigonly_codellama-7b_temperature=0.8_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"codellama\",\n",
    "    #     \"tokenizer\": \"codellama/CodeLlama-7b-hf\",\n",
    "    # },\n",
    "    # # Defects4J codellama-7b sigonly t=0.8,\n",
    "    # {\n",
    "    #     \"identifier\": \"Defects4J codellama-7b sigonly t=0.8\",\n",
    "    #     \"greedy_path\": \"data/codellama-7b/defects4j/greedy/candidates_Defects4J_sigonly_codellama-7b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/codellama-7b/defects4j/multiple/candidates_Defects4J_sigonly_codellama-7b_temperature=0.8_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"codellama\",\n",
    "    #     \"tokenizer\": \"codellama/CodeLlama-7b-hf\",\n",
    "    # },\n",
    "    # # GitBugJava codellama-7b sigonly t=0.8,\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava codellama-7b sigonly t=0.8\",\n",
    "    #     \"greedy_path\": \"data/codellama-7b/gitbug-java/greedy/candidates_GitBugJava_sigonly_codellama-7b_temperature=0.0_n_samples=1_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/codellama-7b/gitbug-java/multiple/candidates_GitBugJava_sigonly_codellama-7b_temperature=0.8_generation_strategy=beam_search_num_beams=10_num_return_sequences=10.jsonl\",\n",
    "    #     \"method\": \"codellama\",\n",
    "    #     \"tokenizer\": \"codellama/CodeLlama-7b-hf\",\n",
    "    # },\n",
    "\n",
    "    # ====================================================\n",
    "    # Berzelius data\n",
    "    # ====================================================\n",
    "    # {\n",
    "    #     \"identifier\": \"HumanEvalJava gpt-4o-mini sigonly-instruct\",\n",
    "    #     \"greedy_path\": \"data/humaneval-java/gpt-4o-mini/greedy/candidates_HumanEvalJava_sigonly-instruct_openai-chatcompletion_model_name=gpt-4o-mini_generation_strategy=beam_search_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/humaneval-java/gpt-4o-mini/multiple/candidates_HumanEvalJava_sigonly-instruct_openai-chatcompletion_model_name=gpt-4o-mini_max_length=4096_temperature=0.8_generation_strategy=sampling_num_return_sequences=50.jsonl\",\n",
    "    #     \"method\": \"openai-instruct\",\n",
    "    #     \"tokenizer\": \"Xenova/gpt-4o\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"GitBugJava gpt-4o-mini sigonly-instruct\",\n",
    "    #     \"greedy_path\": \"data/gitbug-java/gpt-4o-mini/greedy/candidates_GitBugJava_sigonly-instruct_openai-chatcompletion_model_name=gpt-4o-mini_generation_strategy=beam_search_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/gitbug-java/gpt-4o-mini/multiple/candidates_GitBugJava_sigonly-instruct_openai-chatcompletion_model_name=gpt-4o-mini_max_length=4096_temperature=0.8_generation_strategy=sampling_num_return_sequences=50.jsonl\",\n",
    "    #     \"method\": \"openai-instruct\",\n",
    "    #     \"tokenizer\": \"Xenova/gpt-4o\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"identifier\": \"Defects4J gpt-4o-mini sigonly-instruct\",\n",
    "    #     \"greedy_path\": \"data/defects4j/gpt-4o-mini/greedy/candidates_Defects4J_sigonly-instruct_openai-chatcompletion_model_name=gpt-4o-mini_generation_strategy=beam_search_num_return_sequences=1.jsonl\",\n",
    "    #     \"multiple_path\": \"data/defects4j/gpt-4o-mini/multiple/candidates_Defects4J_sigonly-instruct_openai-chatcompletion_model_name=gpt-4o-mini_max_length=4096_temperature=0.8_generation_strategy=sampling_num_return_sequences=50.jsonl\",\n",
    "    #     \"method\": \"openai-instruct\",\n",
    "    #     \"tokenizer\": \"Xenova/gpt-4o\",\n",
    "    # },\n",
    "    {\n",
    "        \"identifier\": \"humaneval-java\",\n",
    "        \"greedy_path\": \"data/humaneval-java/meta-llama/CodeLlama-7b-Instruct-hf/greedy/candidates_HumanEvalJava_sigonly-instruct_codellama-instruct_model_name=meta-llama:CodeLlama-7b-Instruct-hf_max_length=4096_generation_strategy=beam_search_num_return_sequences=1.jsonl\",\n",
    "        \"multiple_path\": \"data/humaneval-java/candidates_HumanEvalJava_sigonly-instruct_codellama-instruct_model_name=meta-llama:CodeLlama-7b-Instruct-hf_max_length=4096_temperature=0.05_generation_strategy=sampling_num_return_sequences=10_all.jsonl\",\n",
    "        \"method\": \"huggingface\",\n",
    "        \"tokenizer\": \"meta-llama/CodeLlama-7b-hf\",\n",
    "    },\n",
    "    {\n",
    "        \"identifier\": \"gitbug-java\",\n",
    "        \"greedy_path\": \"data/gitbug-java/meta-llama/CodeLlama-7b-Instruct-hf/greedy/candidates_GitBugJava_sigonly-instruct_codellama-instruct_model_name=meta-llama:CodeLlama-7b-Instruct-hf_max_length=4096_generation_strategy=beam_search_num_return_sequences=1.jsonl\",\n",
    "        \"multiple_path\": \"data/gitbug-java/candidates_GitBugJava_sigonly-instruct_codellama-instruct_model_name=meta-llama:CodeLlama-7b-Instruct-hf_max_length=4096_temperature=0.05_generation_strategy=sampling_num_return_sequences=10_all.jsonl\",\n",
    "        \"method\": \"huggingface\",\n",
    "        \"tokenizer\": \"meta-llama/CodeLlama-7b-hf\",\n",
    "    },\n",
    "    {\n",
    "        \"identifier\": \"defects4j\",\n",
    "        \"greedy_path\": \"data/defects4j/meta-llama/CodeLlama-7b-Instruct-hf/greedy/candidates_Defects4J_sigonly-instruct_codellama-instruct_model_name=meta-llama:CodeLlama-7b-Instruct-hf_max_length=4096_generation_strategy=beam_search_num_return_sequences=1.jsonl\",\n",
    "        \"multiple_path\": \"data/defects4j/candidates_Defects4J_sigonly-instruct_codellama-instruct_model_name=meta-llama:CodeLlama-7b-Instruct-hf_max_length=4096_temperature=0.05_generation_strategy=sampling_num_return_sequences=10_all.jsonl\",\n",
    "        \"method\": \"huggingface\",\n",
    "        \"tokenizer\": \"meta-llama/CodeLlama-7b-hf\",\n",
    "    },\n",
    "]\n",
    "# Fast filter\n",
    "# FILTER_FUN = lambda conf: \"codellama/CodeLlama-7b-hf\" in conf[\"tokenizer\"]\n",
    "# FILTER_FUN = lambda conf: \"starcoder\" in conf[\"identifier\"].split() and \"HumanEvalJava\" in conf[\"identifier\"].split()\n",
    "# conf_list = list(filter(FILTER_FUN, conf_list))\n",
    "\n",
    "skipped_list = []\n",
    "invalid_multiple_candidates_list = []\n",
    "invalid_greedy_candidates_list = []\n",
    "peaks_list = []\n",
    "dists_list = []\n",
    "for conf in conf_list:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(conf[\"tokenizer\"])\n",
    "    run_identifier = conf[\"identifier\"]\n",
    "    greedy_path = conf[\"greedy_path\"]\n",
    "    multiple_path = conf[\"multiple_path\"]\n",
    "    # Load the multiple generation data\n",
    "    if multiple_path.endswith(\".gz\"):\n",
    "        data = load_jsonl(multiple_path, gzip.open)\n",
    "    else:\n",
    "        data = load_jsonl(multiple_path)\n",
    "    multiple_samples_taskset = data\n",
    "\n",
    "    # Load the greedy generation data\n",
    "    if greedy_path.endswith(\".gz\"):\n",
    "        data = load_jsonl(greedy_path, gzip.open)\n",
    "    else:\n",
    "        data = load_jsonl(greedy_path)\n",
    "    greedy_samples_taskset = data\n",
    "    \n",
    "    # dataset speficic functions\n",
    "    match conf[\"method\"]:\n",
    "        case \"openai-instruct\":\n",
    "            samples_fun, greedy_sample_fun = openai_get_samples_instruct, openai_get_samples_greedy_instruct\n",
    "        case \"huggingface\":\n",
    "            samples_fun, greedy_sample_fun = get_samples, get_samples_greedy\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown method: {conf['method']}\")\n",
    "    \n",
    "    # get greedy samples\n",
    "    greedy_samples_taskset_map = {s[\"identifier\"]: greedy_sample_fun(s) for s in greedy_samples_taskset}\n",
    "    \n",
    "    n_samples = len(multiple_samples_taskset)\n",
    "    Skipped = [False for _ in range(n_samples)]\n",
    "    Dists = [None for _ in range(n_samples)]\n",
    "    Peaks = [None for _ in range(n_samples)]\n",
    "    InvalidMultipleSamples = [0 for _ in range(n_samples)]\n",
    "    InvalidGreedySamples = [0 for _ in range(n_samples)]\n",
    "    for i, task in enumerate(multiple_samples_taskset):\n",
    "        task_identifier = task[\"identifier\"]\n",
    "        # Tokenize the samples\n",
    "        samples = samples_fun(task)\n",
    "        if not samples:\n",
    "            Skipped[i] = \"No samples generated\"\n",
    "            continue\n",
    "        correct_samples = list(filter(None, samples))\n",
    "        InvalidMultipleSamples[i] = len(samples) - len(correct_samples)\n",
    "        if not correct_samples:\n",
    "            Skipped[i] = \"No valid samples\"\n",
    "            continue\n",
    "        samples: List[Tokens] = [\n",
    "            tokenize_code(s, tokenizer, max_length) for s in samples\n",
    "        ]\n",
    "        # Tokenize the greedy sample\n",
    "        if task_identifier not in greedy_samples_taskset_map:\n",
    "            Skipped[i] = \"No corresponding greedy sample\"\n",
    "            continue\n",
    "        gready_sample_str = greedy_samples_taskset_map[task_identifier]\n",
    "        if not gready_sample_str:\n",
    "            InvalidGreedySamples[i] = 1\n",
    "            Skipped[i] = \"Invalid greedy sample\"\n",
    "            continue\n",
    "        gready_sample: Tokens = tokenize_code(gready_sample_str, tokenizer, max_length)\n",
    "        # Calculate the edit distance distribution\n",
    "        dist, ml = get_edit_distance_distribution_star(samples, gready_sample)\n",
    "        Dists[i] = dist  # Add bug dists to benchmark dists\n",
    "        peak = calculate_ratio(dist, alpha * ml)\n",
    "        Peaks[i] = peak\n",
    "\n",
    "    # Add results to the lists\n",
    "    skipped_list.append(Skipped)\n",
    "    dists_list.append(Dists)  # Add benchmark dists to job dists\n",
    "    peaks_list.append(Peaks)\n",
    "    invalid_multiple_candidates_list.append(InvalidMultipleSamples)\n",
    "    invalid_greedy_candidates_list.append(InvalidGreedySamples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Save results to .json file as {benchmark-bug_id: str -> [edit_distance_star: int]}\n",
    "\n",
    "CDD_DATA_CACHE = \"cdd-data-cache.json\"\n",
    "\n",
    "bug_cdd_data = {}\n",
    "for conf, bench_dists in zip(conf_list, dists_list):\n",
    "    # Read bugs\n",
    "    bench_identifier = conf[\"identifier\"]\n",
    "    greedy_path = conf[\"greedy_path\"]\n",
    "    with open(greedy_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    data = map(json.loads, lines)\n",
    "\n",
    "    for row, bug_dists in zip(data, bench_dists):\n",
    "        bug_identifier = f\"{bench_identifier}-{row['identifier']}\"\n",
    "        bug_cdd_data[bug_identifier] = bug_dists\n",
    "\n",
    "with open(CDD_DATA_CACHE, \"w\") as f:\n",
    "    f.write(json.dumps(bug_cdd_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dists \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dists_list):\n\u001b[1;32m     13\u001b[0m     d_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, dists)  \u001b[38;5;66;03m# Remove None values\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     d_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_full\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Flatten the list\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     d_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(d_full)\n\u001b[1;32m     16\u001b[0m     total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(d_full)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "# We have a list of identifiers and a list of edit distances\n",
    "# We want a line plot of multiple lines\n",
    "# - x-axis is the edit distance\n",
    "# - y-axis is the ratio of samples that have an equal edit-distance\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "identifiers = [e[\"identifier\"] for e in conf_list]\n",
    "for i, dists in enumerate(dists_list):\n",
    "    d_full = filter(None, dists)  # Remove None values\n",
    "    d_full = sum(lambda x, y: x + y, d_full)  # Flatten the list\n",
    "    d_full = list(d_full)\n",
    "    total = sum(d_full)\n",
    "    count = Counter(d_full)\n",
    "    x, y = zip(*sorted(count.items(), key=lambda x: x[0]))\n",
    "    y = [c / total for c in y]\n",
    "    plt.plot(x, y, label=identifiers[i])\n",
    "plt.xlabel(\"Edit distance\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Generate a bar chart showing the prevalence of zero distance samples relative to the total number of samples\n",
    "\n",
    "identifiers = [e[\"identifier\"] for e in conf_list]\n",
    "index = np.arange(len(identifiers))  # The label locations\n",
    "\n",
    "zero_distance_ratios = []\n",
    "non_zero_distance_ratios = []\n",
    "\n",
    "for i, dists in enumerate(dists_list):\n",
    "    d_full = filter(None, dists)  # Remove None values\n",
    "    d_full = reduce(lambda x, y: x + y, d_full)  # Flatten the list\n",
    "    d_full = list(d_full)\n",
    "    count = Counter(d_full)\n",
    "    \n",
    "    zero_distance = count.get(0, 0)\n",
    "    total_samples = sum(count.values())\n",
    "    \n",
    "    zero_distance_ratio = zero_distance / total_samples\n",
    "    non_zero_distance_ratio = 1 - zero_distance_ratio\n",
    "    \n",
    "    zero_distance_ratios.append(zero_distance_ratio)\n",
    "    non_zero_distance_ratios.append(non_zero_distance_ratio)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "\n",
    "p1 = ax.bar(index, zero_distance_ratios, bar_width, label='Zero Distance Ratio')\n",
    "p2 = ax.bar(index, non_zero_distance_ratios, bar_width, bottom=zero_distance_ratios, label='Non-Zero Distance Ratio')\n",
    "\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('Ratio')\n",
    "ax.set_title('Prevalence of Zero and Non-Zero Distance Samples by Dataset')\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(identifiers)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, {163, 199, 835}, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = len(dists_list)\n",
    "n_bugs = set(len(e) for e in dists_list)\n",
    "n_samples = len(dists_list[0][0])\n",
    "n_data, n_bugs, n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 23)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of invalid samples (could not be transformed and tokenized)\n",
    "i = 2\n",
    "n_tasks = len(dists_list[i])\n",
    "n_no_samples = len(list(filter(lambda e: e == \"No samples generated\", skipped_list[i])))\n",
    "n_tasks - n_no_samples, sum(invalid_multiple_candidates_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({False: 163}),\n",
       " Counter({'No samples generated': 104, False: 95}),\n",
       " Counter({False: 464,\n",
       "          'No samples generated': 343,\n",
       "          'No valid samples': 23,\n",
       "          'Invalid greedy sample': 5})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip reason counter\n",
    "[Counter(e) for e in skipped_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elleelleaime-Ymc4Ofxq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
